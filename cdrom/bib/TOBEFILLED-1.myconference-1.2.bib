@InProceedings{lal-rayson-elhaj:0:myconference,
  author    = {Lal, Daisy Monika  and  Rayson, Paul  and  El-Haj, Mo},
  title     = {Hindi Reading Comprehension: Do Large Language Models Exhibit Semantic Understanding?},
  booktitle      = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month          = {TOBEFILLED-June},
  year           = {TOBEFILLED-1},
  address        = {TOBEFILLED-Ann Arbor, Michigan},
  publisher      = {Association for Computational Linguistics},
  pages     = {12--22},
  abstract  = {In this study, we explore the performance of four advanced Generative AI modelsâ€”GPT-3.5, GPT-4, Llama3, and HindiGPT, for the Hindi reading comprehension task. Using a zero-shot, instruction-based prompting strategy, we assess model responses through a comprehensive triple evaluation framework using the HindiRC dataset. Our framework combines (1) automatic evaluation using ROUGE, BLEU, BLEURT, METEOR, and Cosine Similarity; (2) rating-based assessments focussing on correctness, comprehension depth, and informativeness; and (3) preference-based selection to identify the best responses. Human ratings indicate that GPT-4 outperforms the other LLMs on all parameters, followed by HindiGPT, GPT-3.5, and then Llama3. Preference-based evaluation similarly placed GPT-4 (80\%) as the best model, followed by HindiGPT(74\%). However, automatic evaluation showed GPT-4 to be the lowest performer on n-gram metrics, yet the best performer on semantic metrics, suggesting it captures deeper meaning and semantic alignment over direct lexical overlap, which aligns with its strong human evaluation scores. This study also highlights that even though the models mostly address literal factual recall questions with high precision, they still face the challenge of specificity and interpretive bias at times.},
  url       = {https://aclanthology.org/TOBEFILLED-1.myconference-1.2}
}

