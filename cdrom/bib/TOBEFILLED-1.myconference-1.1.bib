@InProceedings{kazi-rahim-khoja:0:myconference,
  author    = {kazi, Samreen  and  Rahim, Maria  and  Khoja, Shakeel Ahmed},
  title     = {Crossing Language Boundaries: Evaluation of Large Language Models on Urdu-English Question Answering},
  booktitle      = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month          = {TOBEFILLED-June},
  year           = {TOBEFILLED-1},
  address        = {TOBEFILLED-Ann Arbor, Michigan},
  publisher      = {Association for Computational Linguistics},
  pages     = {1--11},
  abstract  = {This study evaluates the question-answering capabilities of Large Language Models (LLMs) in Urdu, addressing a critical gap in low-resource language processing. Four models GPT-4, mBERT, XLM-R, and mT5 are assessed across monolingual, cross-lingual, and mixed-language settings using the UQuAD1.0 and SQuAD2.0 datasets. Results reveal significant performance gaps between English and Urdu processing, with GPT-4 achieving the highest F1 scores (89.1\% in English, 76.4\% in Urdu) while demonstrating relative robustness in cross-lingual scenarios. Boundary detection and translation mismatches emerge as primary challenges, particularly in cross-lingual settings. The study further demonstrates that question complexity and length significantly impact performance, with factoid questions yielding 14.2\% higher F1 scores compared to complex questions. These findings establish important benchmarks for enhancing LLM performance in low-resource languages and identify key areas for improvement in multilingual question-answering systems.},
  url       = {https://aclanthology.org/TOBEFILLED-1.myconference-1.1}
}

