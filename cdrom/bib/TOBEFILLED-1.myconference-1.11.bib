@InProceedings{bandaranayake-usoof:0:myconference,
  author    = {Bandaranayake, Isuru  and  Usoof, Hakim},
  title     = {Sentiment Analysis of Sinhala News Comments Using Transformers},
  booktitle      = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month          = {TOBEFILLED-June},
  year           = {TOBEFILLED-1},
  address        = {TOBEFILLED-Ann Arbor, Michigan},
  publisher      = {Association for Computational Linguistics},
  pages     = {100--108},
  abstract  = {Sentiment analysis has witnessed significant advancements with the emergence of deep learning models such as transformer models. Transformer models adopt the mechanism of self-attention and have achieved state-of-the-art performance across various natural language processing (NLP) tasks, including sentiment analysis. However, limited studies are exploring the application of these recent advancements in sentiment analysis of Sinhala text. This study addresses this research gap by employing transformer models such as BERT, DistilBERT, RoBERTa, and XLM-RoBERTa (XLM-R) for sentiment analysis of Sinhala News comments. This study was conducted for 4 classes: positive, negative, neutral, and conflict, as well as for 3 classes: positive, negative, and neutral. It revealed that the XLM-R-large model outperformed the other four models, and the transformer models used in previous studies for the Sinhala language. The XLM-R-large model achieved an accuracy of 65.84\% and a macro-F1 score of 62.04\% for sentiment analysis with four classes and an accuracy of 75.90\% and a macro-F1 score of 72.31\% for three classes.},
  url       = {https://aclanthology.org/TOBEFILLED-1.myconference-1.11}
}

