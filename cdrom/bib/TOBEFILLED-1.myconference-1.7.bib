@InProceedings{goel-sadat:0:myconference,
  author    = {Goel, Rashi  and  Sadat, Fatiha},
  title     = {Studying the Effect of Hindi Tokenizer Performance on Downstream Tasks},
  booktitle      = {TOBEFILLED-Proceedings of the Second Workshop on Building Educational Applications Using NLP},
  month          = {TOBEFILLED-June},
  year           = {TOBEFILLED-1},
  address        = {TOBEFILLED-Ann Arbor, Michigan},
  publisher      = {Association for Computational Linguistics},
  pages     = {71--76},
  abstract  = {This paper deals with a study on the effect of training data size and tokenizer performance for Hindi language on the eventual downstream model performance and comprehension. Multiple monolingual Hindi tokenizers are trained for large language models such as BERT and intrinsic and extrinsic evaluations are performed on multiple Hindi datasets. The objective of this study is to understand the precise effects of tokenizer performance on downstream task performance to gain insight on how to develop better models for low-resource languages.},
  url       = {https://aclanthology.org/TOBEFILLED-1.myconference-1.7}
}

